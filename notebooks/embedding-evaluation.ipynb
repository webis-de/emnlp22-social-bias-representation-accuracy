{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Embedding evaluation\n",
    "\n",
    "This notebook contains the code to evaluate the different embedding models generated in the `embedding-generation.ipynb` notebook.\n",
    "\n",
    "Paper reference: _Splieth√∂ver, Keiff, Wachsmuth (2022): \"No Word Embedding Model Is Perfect: Evaluating the Representation Accuracy for Social Bias in the Media\", EMNLP 2022, Abu Dhabi._\n",
    "\n",
    "Code & Data reference: https://github.com/webis-de/EMNLP-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data preparation and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following two cells for any of the embedding models. They load the most common packages and set commonly used variables. They are necessary to run the training cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "from os import chdir, getcwd, listdir, path\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "from wefe.metrics import WEAT\n",
    "from wefe.word_embedding_model import WordEmbeddingModel\n",
    "from wefe.query import Query\n",
    "\n",
    "PARENT_DIR = path.abspath(\"../src\")\n",
    "sys.path.append(PARENT_DIR)\n",
    "from embedding_bias.config import (\n",
    "    CRAWL_FIRST_YEAR, CRAWL_LAST_YEAR, SENTENCE_ENDING_TOKEN, NEWS_ARTICLE_DB_NAME)\n",
    "from embedding_bias.preprocessing import preprocess_text\n",
    "from embedding_bias.util import *\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = path.join(PARENT_DIR.parent, \"data\")\n",
    "DB_PATH = path.join(DATA_DIR, \"raw\", NEWS_ARTICLE_DB_NAME)\n",
    "ALLSIDES_RANKING_PATH = path.join(DATA_DIR, \"raw\", \"allsides-ranking.csv\")\n",
    "OUTLET_CONFIG_PATH = path.join(DATA_DIR, \"raw\", \"outlet-config.json\")\n",
    "WORD_SETS_PATH = path.join(DATA_DIR, \"raw\", \"word-sets.json\")\n",
    "\n",
    "# Target sqlite database\n",
    "target_db_connection = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Outlet config file\n",
    "outlet_config = pd.read_json(OUTLET_CONFIG_PATH)\n",
    "outlet_selection = outlet_config\n",
    "\n",
    "# Word sets\n",
    "with open(WORD_SETS_PATH, \"r\") as f:\n",
    "    word_sets = json.load(f)\n",
    "\n",
    "# Allsides ranking\n",
    "allsides_ranking = pd.read_csv(ALLSIDES_RANKING_PATH)\n",
    "\n",
    "# Evaluation metrics\n",
    "METRICS = [WEAT()]\n",
    "\n",
    "# Groups of political orientations\n",
    "orientation_groups = {\n",
    "    \"left\": [\"Lean Left\", \"Left\"],\n",
    "    \"center\": [\"Center\"],\n",
    "    \"right\": [\"Lean Right\", \"Right\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Word similarity benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding_evaluation.evaluate import Evaluation\n",
    "from embedding_evaluation.load_embedding import load_embedding_textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_EVAL_DATA_DIR = path.join(\n",
    "    PARENT_DIR, \"embedding_evaluation\", \"embedding_evaluation\", \"data\")\n",
    "os.environ[\"EMBEDDING_EVALUATION_DATA_PATH\"] = SIM_EVAL_DATA_DIR\n",
    "\n",
    "BENCHMARK_RESULTS_DIR = path.join(DATA_DIR, \"processed\", \"embedding-benchmark-results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Representation Degeneration error analysis test generation\n",
    "_Generates the test files needed for the representation degeneration error analysis. Needs to be run only the first time. After that, the test files are saved to disk._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open tokenized articles cache\n",
    "W2V_ARTICLE_PREPROCESS_CACHE = path.join(\n",
    "    DATA_DIR, \"processed\", \"nato\", \"articles-preproc-cache.pkl\")\n",
    "\n",
    "# Embedding model similarity evaluation files directory\n",
    "SIM_EVAL_DIR = path.join(DATA_DIR, \"processed\", \"embedding-benchmark-results\")\n",
    "MODEL_SIM_EVAL_RESULTS = listdir(SIM_EVAL_DIR)\n",
    "\n",
    "# Number of least common tokens to return\n",
    "LEAST_COMMON = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "with open(W2V_ARTICLE_PREPROCESS_CACHE, \"rb\") as f:\n",
    "    articles = pickle.load(f)\n",
    "\n",
    "# Retrieve evalaution tokens from disk\n",
    "men_eval_file = path.join(SIM_EVAL_DATA_DIR, \"men\", \"MEN_dataset_natural_form_full\")\n",
    "with open(men_eval_file, \"r\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    men_pairs = [line.split(\" \") for line in lines][1:]\n",
    "    men_tokens = [token for pair in men_pairs for token in pair[:-1]]\n",
    "\n",
    "ws353_eval_file = path.join(SIM_EVAL_DATA_DIR, \"wordsim\", \"combined.csv\")\n",
    "with open(ws353_eval_file, \"r\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    ws353_pairs = [line.split(\",\") for line in lines][1:]\n",
    "    ws353_tokens = [token for pair in ws353_pairs for token in pair[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening article tokens, as there is no need for sentence structure in this case.\n",
    "if not \"tokens_flat\" in articles.columns:\n",
    "    print(\"Flattening article tokens.\")\n",
    "    articles[\"tokens_flat\"] = articles.text_prep.progress_apply(lambda x: [t for s in x for t in s])\n",
    "\n",
    "# Count tokens in each orientation to retrieve the least common ones\n",
    "orientation_least_common = {}\n",
    "print(\"Retrieving least common tokens.\")\n",
    "for orientation, grouping in orientation_groups.items():\n",
    "    orientation_articles = articles[articles.orientation.isin(grouping)].tokens_flat\n",
    "    all_tokens = [token for article in tqdm(orientation_articles) for token in article]\n",
    "    token_couter = Counter(all_tokens)\n",
    "\n",
    "    test_least_common = {}\n",
    "    least_common = sorted(token_couter.most_common(), key=lambda x: x[1])\n",
    "    test_least_common[\"men\"] = [token[0] for token in least_common if token[0] in men_tokens][:LEAST_COMMON]\n",
    "    test_least_common[\"ws353\"] = [token[0] for token in least_common if token[0] in ws353_tokens][:LEAST_COMMON]\n",
    "\n",
    "    orientation_least_common[orientation] = test_least_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve evaluation pairs containing the rare tokens\n",
    "orientation_rare_pairs = {}\n",
    "for orientation, tests in orientation_least_common.items():\n",
    "    test_rare_pairs = {}\n",
    "    for test, rare_tokens in tests.items():\n",
    "        pairs = men_pairs if test == \"men\" else ws353_pairs\n",
    "        rare_pairs = [(pair[0], pair[1], pair[2]) for pair in pairs if pair[0] in rare_tokens or pair[1] in rare_tokens]\n",
    "        test_rare_pairs[test] = rare_pairs\n",
    "\n",
    "    orientation_rare_pairs[orientation] = test_rare_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export rare tokens into a file format that the evaluation library understands\n",
    "for orientation, tests in orientation_rare_pairs.items():\n",
    "    for test, pairs in tests.items():\n",
    "        with open(f\"{SIM_EVAL_DATA_DIR}/{test}-rare/{orientation}.test\", \"w\") as f:\n",
    "            for pair in pairs:\n",
    "                f.write(f\"{pair[0]} {pair[1]} {float(pair[2])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### word2vec models (Static embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = path.join(DATA_DIR, \"models\", \"nato-w2v\")\n",
    "MODEL_LIST = [\n",
    "    \"left.model\",\n",
    "    \"center.model\",\n",
    "    \"right.model\"]\n",
    "\n",
    "# Load previously trained models from disk\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(MODEL_LIST):\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(MODEL_LIST)} Loading model\", model)\n",
    "    model_file_name = path.join(MODELS_PATH, model)\n",
    "    loaded_models[model] = Word2Vec.load(model_file_name).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark models\n",
    "full_results, benchmark_results = benchmark_models(loaded_models, return_full_json=True)\n",
    "model_results_file = path.join(BENCHMARK_RESULTS_DIR, f\"{MODEL_NAME}.json\")\n",
    "with open(model_results_file, \"w\") as f:\n",
    "    json.dump(full_results, f, indent=4)\n",
    "\n",
    "print(benchmark_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Decontextualized embeddings (Decontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"contextualized2static\"\n",
    "MODELS_PATH = path.join(DATA_DIR, \"models\", MODEL_NAME)\n",
    "MODELS = [\n",
    "    \"left.model\",\n",
    "    \"center.model\",\n",
    "    \"right.model\"]\n",
    "\n",
    "# Load models from disk\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(MODELS):\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(MODELS)} Loading model\", model)\n",
    "    model_file_name = path.join(MODELS_PATH, model)\n",
    "    loaded_models[model] = KeyedVectors.load_word2vec_format(model_file_name, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark models\n",
    "full_results, benchmark_results = benchmark_models(loaded_models, return_full_json=True)\n",
    "model_results_file = path.join(BENCHMARK_RESULTS_DIR, f\"{MODEL_NAME}.json\")\n",
    "with open(model_results_file, \"w\") as f:\n",
    "    json.dump(full_results, f, indent=4)\n",
    "\n",
    "print(benchmark_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Frequency agnostic embeddings (FreqAgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAGE_PATH = path.join(PARENT_DIR, \"Frequency-Agnostic\")\n",
    "\n",
    "normal_base_dir = getcwd()\n",
    "chdir(path.join(FRAGE_PATH, \"lm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import torch\n",
    "\n",
    "# FRAGE imports\n",
    "import model\n",
    "import data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained FRAGE model and corpus for each orientation\n",
    "MODEL_NAME = \"frage-lstm\"\n",
    "model_files = [\n",
    "    (\"left-frage-v0--b600.pt\", \"left/frage-corpus.7899431f957ce95000ec90d10e1fa2d0.data\"),\n",
    "    (\"center-frage-v1--b600.pt\", \"center/frage-corpus.f1ec93b6d6495c8ade1ce55d0f0c99e7.data\"),\n",
    "    (\"right-frage-v0--b600.pt\", \"right/frage-corpus.b381924fee77a9f10329361df32cf68d.data\")]\n",
    "\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(model_files):\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(model_files)} Loading model\", model[0])\n",
    "    model_path = path.join(DATA_DIR, \"models\", MODEL_NAME, model[0])\n",
    "    kv_model_path = f\"{model_path}.kv\"\n",
    "\n",
    "    if not path.exists(kv_model_path):\n",
    "        print(\"No cache found. Retrieving embedding from trained model.\")\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            pt_model, criterion, optimizer, epoch = torch.load(f)\n",
    "\n",
    "        model_corpus_name = path.join(DATA_DIR, \"processed\", \"corpus-awd-lstm-format\", model[1])\n",
    "        model_corpus = torch.load(model_corpus_name)\n",
    "        model_dictionary = model_corpus.dictionary.word2idx\n",
    "\n",
    "        print(\"Retrieving token/vector dict.\")\n",
    "        embedding_dict = get_embedding_dict_from_pytorch(pt_model, model_dictionary)\n",
    "        loaded_models[model[0]] = dict_to_word2vec_file(embedding_dict, kv_model_path)\n",
    "    else:\n",
    "        print(\"Output file already exists. Loading directly instead.\")\n",
    "        loaded_models[model[0]] = KeyedVectors.load_word2vec_format(kv_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark models\n",
    "full_results, benchmark_results = benchmark_models(loaded_models, return_full_json=True)\n",
    "model_results_file = path.join(BENCHMARK_RESULTS_DIR, f\"{MODEL_NAME}.json\")\n",
    "with open(model_results_file, \"w\") as f:\n",
    "    json.dump(full_results, f, indent=4)\n",
    "\n",
    "print(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(normal_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Fine-tuned BERT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models as KeyedVector instances\n",
    "MODEL_NAME = \"bert-finetuned\"\n",
    "MODELS_PATH = path.join(DATA_DIR, \"models\", MODEL_NAME)\n",
    "MODEL_LIST = [\n",
    "    (\"left\", \"195500\"),\n",
    "    (\"center\", \"32500\"),\n",
    "    (\"right\", \"66500\"),\n",
    "    (\"bert-base\", \"-1\")]\n",
    "\n",
    "vocabulary = get_test_vocabulary(word_sets=word_sets, similarity_eval_data_path=SIM_EVAL_DATA_DIR)\n",
    "vocab_list = list(vocabulary)\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(MODEL_LIST):\n",
    "    # Load the model to evaluate. The BERT base model is identified by the \"-1\" checkpoint number.\n",
    "    if model[1] == \"-1\":\n",
    "        model_name = f\"{model[0]}.model\"\n",
    "        pt_model_path = path.join(MODELS_PATH, model[0])\n",
    "    else:\n",
    "        model_name = f\"{model[0]}-c{model[1]}.model\"\n",
    "        pt_model_path = path.join(MODELS_PATH, model[0], f\"checkpoint-{model[1]}\")\n",
    "\n",
    "    kv_model_path = path.join(MODELS_PATH, model_name)\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(MODEL_LIST)} Loading model\", model_name)\n",
    "\n",
    "    # If the model does not yet exist as KeyedVector file, create it first for easier evaluation\n",
    "    if not path.exists(kv_model_path):\n",
    "        print(f\"{model_name} doesn't exist as KeyedVector instance. Generating first...\")\n",
    "        # Load BERT model from file using the flair library\n",
    "        if model[0] == \"bert-base\":\n",
    "            embeddings = TransformerWordEmbeddings(\"bert-base-uncased\")\n",
    "        else:\n",
    "            embeddings = TransformerWordEmbeddings(\n",
    "                model=pt_model_path,\n",
    "                name=model_name)\n",
    "\n",
    "        embedding_dict = {}\n",
    "        for token in vocabulary:\n",
    "            sent = Sentence(token)\n",
    "            embeddings.embed(sent)\n",
    "            embedding_dict[token] = sent[0].embedding\n",
    "\n",
    "        with open(f\"{kv_model_path}\", \"w\") as f:\n",
    "            f.write(f\"{len(embedding_dict)} {len(embedding_dict[vocab_list[0]])}\\n\")\n",
    "            for token in vocabulary:\n",
    "                token_vector = \" \".join([str(d) for d in embedding_dict[token].tolist()])\n",
    "                f.write(f\"{token} {token_vector}\\n\")\n",
    "\n",
    "    model_key = f\"{model[0]}-{model[1]}\"\n",
    "    loaded_models[model_key] = KeyedVectors.load_word2vec_format(kv_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark models\n",
    "full_results, benchmark_results = benchmark_models(loaded_models, return_full_json=True)\n",
    "model_results_file = path.join(BENCHMARK_RESULTS_DIR, f\"{MODEL_NAME}.json\")\n",
    "with open(model_results_file, \"w\") as f:\n",
    "    json.dump(full_results, f, indent=4)\n",
    "\n",
    "print(benchmark_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Social Bias evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### word2vec models (Static embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = path.join(DATA_DIR, \"models\", \"nato-w2v\")\n",
    "MODEL_LIST = [\n",
    "    \"left.model\",\n",
    "    \"center.model\",\n",
    "    \"right.model\"]\n",
    "\n",
    "# Load models from disk\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(MODEL_LIST):\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(MODEL_LIST)} Loading model\", model)\n",
    "    model_file_name = path.join(MODELS_PATH, model)\n",
    "    loaded_models[model] = Word2Vec.load(model_file_name).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all loaded models using specified metrics\n",
    "evaluation_results = evaluate_models(\n",
    "    models=loaded_models,\n",
    "    word_sets=word_sets,\n",
    "    metrics=METRICS,\n",
    "    threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create strip-plot from data (x-axis is metric, blob color is model)\n",
    "# (in this particular case, its a swarm plot -> strip-plot without overlapping points)\n",
    "sns.set_theme()\n",
    "\n",
    "weat_results = evaluation_results[evaluation_results.metric == \"WEAT\"]\n",
    "g = sns.catplot(\n",
    "    data=weat_results, kind=\"swarm\", x=\"bias_type\", y=\"result\", hue=\"model\", height=8, s=20)\n",
    "g.set(ylim=(-2.0, 2.0))\n",
    "plt.title(\"WEAT\")\n",
    "plt.show()\n",
    "\n",
    "print(\"WEAT\\n\", weat_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Decontextualized embeddings (Decontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODELS_PATH = path.join(DATA_DIR, \"models\", \"contextualized2static\")\n",
    "MODELS = [\n",
    "    \"left.model\",\n",
    "    \"center.model\",\n",
    "    \"right.model\"]\n",
    "\n",
    "# Load models from disk\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(MODELS):\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(MODELS)} Loading model\", model)\n",
    "    model_file_name = path.join(MODELS_PATH, model)\n",
    "    loaded_models[model] = KeyedVectors.load_word2vec_format(model_file_name, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "evaluation_results = evaluate_models(\n",
    "    models=loaded_models,\n",
    "    word_sets=word_sets,\n",
    "    metrics=METRICS,\n",
    "    threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create strip-plot from data (x-axis is metric, blob color is model)\n",
    "# (in this particular case, its a swarm plot -> strip-plot without overlapping points)\n",
    "sns.set_theme()\n",
    "\n",
    "weat_results = evaluation_results[evaluation_results.metric == \"WEAT\"]\n",
    "g = sns.catplot(\n",
    "    data=weat_results, kind=\"swarm\", x=\"bias_type\", y=\"result\", hue=\"model\", height=8, s=20)\n",
    "g.set(ylim=(-2.0, 2.0))\n",
    "plt.title(\"WEAT\")\n",
    "plt.show()\n",
    "\n",
    "print(\"WEAT\\n\", weat_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### FRAGE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAGE_PATH = path.join(PARENT_DIR, \"Frequency-Agnostic\")\n",
    "\n",
    "normal_base_dir = getcwd()\n",
    "chdir(path.join(FRAGE_PATH, \"lm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import torch\n",
    "\n",
    "import model\n",
    "import data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained FRAGE model and corpus\n",
    "MODEL_NAME = \"frage-lstm\"\n",
    "model_files = [\n",
    "    (\"left-frage-v0--b600.pt\", \"left/frage-corpus.7899431f957ce95000ec90d10e1fa2d0.data\"),\n",
    "    (\"center-frage-v1--b600.pt\", \"center/frage-corpus.f1ec93b6d6495c8ade1ce55d0f0c99e7.data\"),\n",
    "    (\"right-frage-v0--b600.pt\", \"right/frage-corpus.b381924fee77a9f10329361df32cf68d.data\")]\n",
    "\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(model_files):\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(model_files)} Loading model\", model[0])\n",
    "    model_path = path.join(DATA_DIR, \"models\", MODEL_NAME, model[0])\n",
    "    kv_model_path = f\"{model_path}.kv\"\n",
    "\n",
    "    if not path.exists(kv_model_path):\n",
    "        print(\"No cache found. Retrieving embedding from trained model.\")\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            pt_model, criterion, optimizer, epoch = torch.load(f)\n",
    "\n",
    "        model_corpus_name = path.join(DATA_DIR, \"processed\", \"corpus-awd-lstm-format\", model[1])\n",
    "        model_corpus = torch.load(model_corpus_name)\n",
    "        model_dictionary = model_corpus.dictionary.word2idx\n",
    "\n",
    "        print(\"Retrieving token/vector dict.\")\n",
    "        embedding_dict = get_embedding_dict_from_pytorch(pt_model, model_dictionary)\n",
    "        loaded_models[model[0]] = dict_to_word2vec_file(embedding_dict, kv_model_path)\n",
    "    else:\n",
    "        print(\"Output file already exists. Loading directly instead.\")\n",
    "        loaded_models[model[0]] = KeyedVectors.load_word2vec_format(kv_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "evaluation_results = evaluate_models(\n",
    "    models=loaded_models,\n",
    "    word_sets=word_sets,\n",
    "    metrics=METRICS,\n",
    "    threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create strip-plot from data (x-axis is metric, blob color is model)\n",
    "# (in this particular case, its a swarm plot -> strip-plot without overlapping points)\n",
    "sns.set_theme()\n",
    "\n",
    "weat_results = evaluation_results[evaluation_results.metric == \"WEAT\"]\n",
    "g = sns.catplot(\n",
    "    data=weat_results, kind=\"swarm\", x=\"bias_type\", y=\"result\", hue=\"model\", height=8, s=20)\n",
    "g.set(ylim=(-2.0, 2.0))\n",
    "plt.title(\"WEAT\")\n",
    "plt.show()\n",
    "\n",
    "print(\"WEAT\\n\", weat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(normal_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Fine-tuned BERT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models as KeyedVector instances\n",
    "MODELS_PATH = path.join(DATA_DIR, \"models\", \"bert-finetuned\")\n",
    "\n",
    "MODEL_LIST = [\n",
    "    (\"left\", \"195500\"),\n",
    "    (\"center\", \"32500\"),\n",
    "    (\"right\", \"66500\"),\n",
    "    (\"bert-base\", \"-1\")]\n",
    "\n",
    "vocabulary = get_test_vocabulary(word_sets=word_sets)\n",
    "vocab_list = list(vocabulary)\n",
    "loaded_models = {}\n",
    "for i, model in enumerate(MODEL_LIST):\n",
    "    if model[1] == \"-1\":\n",
    "        model_name = f\"{model[0]}.model\"\n",
    "        pt_model_path = path.join(MODELS_PATH, model[0])\n",
    "    else:\n",
    "        model_name = f\"{model[0]}-c{model[1]}.model\"\n",
    "        pt_model_path = path.join(MODELS_PATH, model[0], f\"checkpoint-{model[1]}\")\n",
    "\n",
    "    kv_model_path = path.join(MODELS_PATH, model_name)\n",
    "    print(\"=\" * 10, f\"{i+1}/{len(MODEL_LIST)} Loading model\", model_name)\n",
    "\n",
    "    if not path.exists(kv_model_path):\n",
    "        print(f\"{model_name} doesn't exist as KeyedVector instance. Generating first...\")\n",
    "        # Load BERT model from file using flair library\n",
    "        if model[0] == \"bert-base\":\n",
    "            embeddings = TransformerWordEmbeddings(\"bert-base-uncased\")\n",
    "        else:\n",
    "            embeddings = TransformerWordEmbeddings(\n",
    "                model=pt_model_path,\n",
    "                name=model_name)\n",
    "\n",
    "        embedding_dict = {}\n",
    "        for token in vocabulary:\n",
    "            sent = Sentence(token)\n",
    "            embeddings.embed(sent)\n",
    "            embedding_dict[token] = sent[0].embedding\n",
    "\n",
    "        with open(f\"{kv_model_path}\", \"w\") as f:\n",
    "            f.write(f\"{len(embedding_dict)} {len(embedding_dict[vocab_list[0]])}\\n\")\n",
    "            for token in vocabulary:\n",
    "                token_vector = \" \".join([str(d) for d in embedding_dict[token].tolist()])\n",
    "                f.write(f\"{token} {token_vector}\\n\")\n",
    "        print(\"Generation done.\")\n",
    "\n",
    "    loaded_models[model] = KeyedVectors.load_word2vec_format(kv_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "evaluation_results = evaluate_models(\n",
    "    models=loaded_models,\n",
    "    word_sets=word_sets,\n",
    "    metrics=METRICS,\n",
    "    threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create strip-plot from data (x-axis is metric, blob color is model)\n",
    "# (in this particular case, its a swarm plot -> strip-plot without overlapping points)\n",
    "sns.set_theme()\n",
    "\n",
    "weat_results = evaluation_results[evaluation_results.metric == \"WEAT\"]\n",
    "g = sns.catplot(\n",
    "    data=weat_results, kind=\"swarm\", x=\"bias_type\", y=\"result\", hue=\"model\", height=8, s=20)\n",
    "g.set(ylim=(-2.0, 2.0))\n",
    "plt.title(\"WEAT\")\n",
    "plt.show()\n",
    "\n",
    "print(\"WEAT\\n\", weat_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Social bias evaluation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_PATH = path.join(DATA_DIR, \"processed\", \"temporal-analysis\")\n",
    "MODELS_PATH = path.join(DATA_DIR, \"models\", \"contextualized2static\", \"temporal\")\n",
    "YEARS = [\n",
    "    \"2010\",\n",
    "    \"2011\",\n",
    "    \"2012\",\n",
    "    \"2013\",\n",
    "    \"2014\",\n",
    "    \"2015\",\n",
    "    \"2016\",\n",
    "    \"2017\",\n",
    "    \"2018\",\n",
    "    \"2019\",\n",
    "    \"2020\",\n",
    "    \"2021\"]\n",
    "ORIENTATIONS = [\n",
    "    \"left\",\n",
    "    \"center\",\n",
    "    \"right\"]\n",
    "\n",
    "# Load models from disk\n",
    "loaded_models = {}\n",
    "for i, orientation in enumerate(ORIENTATIONS):\n",
    "    print(\"=\" * 20, f\"{i+1}/{len(ORIENTATIONS)} Loading models for orientation {orientation}\")\n",
    "    loaded_models[orientation] = {}\n",
    "    for j, year in enumerate(YEARS):\n",
    "        print(\"=\" * 10, f\"{j+1}/{len(YEARS)} {year}\")\n",
    "        model_file_name = path.join(MODELS_PATH, f\"{orientation}-{year}.model\")\n",
    "        loaded_models[orientation][year] = KeyedVectors.load_word2vec_format(model_file_name, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "evaluation_results = pd.DataFrame(columns=[\"orientation\", \"year\", \"bias_type\", \"weat_score\"])\n",
    "for orientation, models in loaded_models.items():\n",
    "    results = evaluate_models(\n",
    "        models=models,\n",
    "        word_sets=word_sets,\n",
    "        metrics=METRICS,\n",
    "        threshold=0.7)\n",
    "\n",
    "    for i, row in results.iterrows():\n",
    "        results_row = [orientation, float(row.model), row.bias_type, row.result]\n",
    "        evaluation_results.loc[len(evaluation_results)] = results_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bias in evaluation_results.bias_type.unique():\n",
    "    result_subset = evaluation_results[evaluation_results.bias_type == bias]\n",
    "    sns.set_theme()\n",
    "    g = sns.lineplot(\n",
    "        data=result_subset,\n",
    "        hue=\"orientation\",\n",
    "        x=\"year\",\n",
    "        y=\"weat_score\",\n",
    "        err_style=\"bars\",\n",
    "        ci=0)\n",
    "    g.set(ylim=(0, 0.5), xlim=(2009, 2022), xticks=range(2010, 2022))\n",
    "    g.set_xticklabels([int(y) for y in result_subset.year.unique()], rotation=45)\n",
    "    plt.title(f\"{bias.capitalize()} bias development over time\")\n",
    "\n",
    "    # Trendline\n",
    "    z = np.polyfit(result_subset.year, result_subset.weat_score, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(result_subset.year, p(result_subset.year), color=\"purple\", linewidth=3)\n",
    "\n",
    "    file_name = f\"{bias}-weat.png\"\n",
    "    plt.savefig(f\"{FIG_PATH}/{file_name}\", dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "61daf9b516095512657e7198d703e6172124fdf4d3e94a95e013ddc8a0dfe156"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
